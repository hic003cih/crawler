單機版爬蟲架構 -> 城市列表解析器(用來分析網站有哪些城市) -> 城市解析器(解析這個城市所有人的名字和url) -> 用戶解析器(解析每個用戶的詳細資料)

解析器(Parser) -> 輸入必須是uft8編碼的文本(如果是其他編碼的,必須先自行轉成utf8,再丟給Parser)

輸入 -> Request{URL,對應Parser}列表 ,Item列表(用戶有價值的數據)

資料傳輸流程 -> 

1.要先有一個中心引擎(Engine),然後由種子(Seed)(你要抓取的起始頁面,可以一個也可以多個)丟Request給他來驅動引擎

2.引擎拿到Request不是馬上做,是先將任務丟到任務對列,然後再從任務對列不斷地取任務出來做

3.引擎從任務對列取得的Request,把裡面的URL挖出來,丟給Fetcher(從網路上獲取數據的模塊,負責建立http連結獲取訊息)處理

4.Fetcher返回一個utf-8(如果網頁不是utf-8須先作轉檔處理)文本給引擎

5.引擎拿到Fetcher返回文本以後,把文本丟給解析器(Parser)

6.解析器返回Request{URL,對應Parser}列表,再將這些將來要做的Request加入任務對列,item則打印出來就可以了

7.就不斷源源不絕的一值做Request的拆解和分析,單機版的因為只取一頁有可能結束,如果是大型網站,可能就會不斷爬取

